 # def __get_irf(self,
    #               h: int,
    #               comp_mat: np.ndarray,
    #               cov_mat: np.ndarray,
    #               rotation: Optional[np.ndarray] = None) -> np.ndarray:
    #     if rotation is None:
    #         rotation = np.eye(self.n_vars)
    #     j = np.concatenate((np.eye(self.n_vars), np.zeros((self.n_vars, self.n_vars * (self.lag_order - 1)))), axis=1)
    #     aa = np.eye(self.n_vars * self.lag_order)
    #     chol = np.linalg.cholesky(cov_mat)  # cholesky gives you the lower triangle in numpy
    #     irf = np.dot(np.dot(np.dot(np.dot(j, aa), j.T), chol), rotation)
    #     irf = irf.reshape((self.n_vars ** 2, -1), order='F')
    #     for i in range(1, h + 1):
    #         # TODO: fix this from here
    #         aa = np.dot(aa, comp_mat)
    #         temp = np.dot(np.dot(np.dot(np.dot(j, aa), j.T), chol), rotation)
    #         temp = temp.reshape((self.n_vars ** 2, -1), order='F')
    #         irf = np.concatenate((irf, temp), axis=1)
    #     return irf
    #
    # def __get_vd(self, irfs: np.ndarray) -> np.ndarray:
    #     irf_mat = np.transpose(irfs)
    #     irf_mat_sq = irf_mat ** 2
    #     irf_mat_sq = irf_mat_sq.reshape((-1, self.n_vars, self.n_vars), order='F')
    #     irf_sq_sum_h = np.cumsum(irf_mat_sq, axis=0)
    #     total_fev = np.sum(irf_sq_sum_h, axis=2)
    #     total_fev_expand = np.expand_dims(total_fev, axis=2)
    #     vd = irf_sq_sum_h / total_fev_expand
    #     vd = vd.T.reshape((self.n_vars ** 2, -1))
    #     return vd
    #
    # def __make_irf_graph(self,
    #                      h: int,
    #                      var_list: List[str],
    #                      shock_list: List[str],
    #                      sigs: Union[List[int], int],
    #                      max_cols: int,
    #                      with_ci: bool,
    #                      save_path: Optional[str] = None) -> None:
    #     # layout
    #     ns = len(shock_list)
    #     nv = len(var_list)
    #     split = nv > max_cols
    #     n_cols = max_cols if split else nv
    #     n_rows = nv // max_cols + 1 if split else 1
    #     x_ticks = range(h)
    #
    #     # plotting
    #     for i in range(ns):
    #         plt.figure(figsize=(n_cols * 10, n_rows * 10))
    #         plt.subplots_adjust(wspace=0.25, hspace=0.35)
    #         color = pt.BlueRed_6.mpl_colors[i]
    #         shock_id = self.shock_names.index(shock_list[i])
    #         for j in range(nv):
    #             ax = plt.subplot(n_rows, n_cols, j + 1)
    #             var_id = self.var_names.index(var_list[j])
    #             row = var_id + shock_id * self.n_vars
    #             plt.plot(x_ticks, self.irf_point_estimate[row, :h + 1], color=color, linewidth=3)
    #             plt.axhline(y=0, color='black', linestyle='-', linewidth=3)
    #             if with_ci:
    #                 for sig, alpha in zip(sigs, alpha_list[1:]):
    #                     plt.fill_between(x_ticks,
    #                                      self.irf_confid_intvl[sig]['lower'][row, :h + 1],
    #                                      self.irf_confid_intvl[sig]['upper'][row, :h + 1],
    #                                      alpha=alpha, edgecolor=color, facecolor=color, linewidth=0)
    #             plt.xlim(0, h)
    #             plt.xticks(list(range(0, h, 5)))
    #             plt.title(var_list[j], font_prop_title, pad=5.)
    #             plt.tick_params(labelsize=25)
    #             labels = ax.get_xticklabels() + ax.get_yticklabels()
    #             [label.set_fontname('Palatino') for label in labels]
    #             if j == 0:
    #                 ax.set_xlabel(date_transfer_dict[self.date_frequency], fontdict=font_prop_xlabels, labelpad=1.)
    #             plt.grid(linestyle='--', linewidth=1.5, color='black', alpha=0.35)
    #             ax.spines['right'].set_visible(False)
    #             ax.spines['top'].set_visible(False)
    #             ax.spines['left'].set_linewidth(1.5)
    #             ax.spines['bottom'].set_linewidth(1.5)
    #         plt.suptitle(shock_list[i], fontproperties=font_prop_suptitle)
    #
    #         # save
    #         if save_path is not None:
    #             full_path = save_path + f'/orth_shock{i}.png'
    #             plt.savefig(full_path, bbox_inches='tight')
    #         plt.show()
    #
    # def __make_vd_graph(self,
    #                     h: int,
    #                     var_list: List[str],
    #                     shock_list: List[str],
    #                     max_cols: int,
    #                     save_path: str) -> None:
    #     nv = len(var_list)
    #     split = nv > max_cols
    #     n_cols = max_cols if split else nv
    #     n_rows = nv // max_cols + 1 if split else 1
    #     x_ticks = range(h)
    #
    #     plt.figure(figsize=(n_cols * 10, n_rows * 10))
    #     plt.subplots_adjust(wspace=0.25, hspace=0.35)
    #
    #     for idxv, var in enumerate(var_list):
    #         accum = np.zeros(h)
    #         ax = plt.subplot(n_rows, n_cols, idxv + 1)
    #         for idxs, sho in enumerate(shock_list):
    #             color = pt.BlueRed_6.mpl_colors[idxs]
    #             shock_id = self.shock_names.index(sho)
    #             var_id = self.var_names.index(var)
    #             row = var_id + shock_id * self.n_vars
    #             plt.plot(x_ticks, self.vd_point_estimate[row, :], color=color, linewidth=3)
    #             accum += self.vd_point_estimate[row, :]
    #             plt.axhline(y=0, color='black', linestyle='-', linewidth=3)
    #         vd_rest = 1 - accum
    #         if np.sum(vd_rest) > 1e-10:
    #             plt.plot(x_ticks, vd_rest, color='k', linewidth=3)
    #         plt.xlim(0, h - 1)
    #         plt.xticks(list(range(0, h, 5)))
    #         plt.title(var, font_prop_title, pad=5.)
    #         plt.tick_params(labelsize=25)
    #         labels = ax.get_xticklabels() + ax.get_yticklabels()
    #         [label.set_fontname('Palatino') for label in labels]
    #         if idxv == 0:
    #             ax.set_xlabel(date_transfer_dict[self.date_frequency], fontdict=font_prop_xlabels, labelpad=1.)
    #         plt.grid(linestyle='--', linewidth=1.5, color='black', alpha=0.35)
    #         ax.spines['right'].set_visible(False)
    #         ax.spines['top'].set_visible(False)
    #         ax.spines['left'].set_linewidth(1.5)
    #         ax.spines['bottom'].set_linewidth(1.5)
    #
    #     plt.suptitle('Variance Decomposition', fontproperties=font_prop_suptitle)
    #     if save_path is not None:
    #         full_path = save_path + '/variance_decomposition.png'
    #         plt.savefig(full_path, bbox_inches='tight')
    #     plt.show()
    #
    # # maybe move to the SVAR
    # # def __make_hd_graph(self,
    # #                     h: int,
    # #                     var: str,
    # #                     shock_list: List[str],
    # #                     hd_start: Optional[datetime.datetime],
    # #                     hd_end: Optional[datetime.datetime],
    # #                     save_path: str) -> None:
    # #     plt.figure(figsize=(10, 10))
    # #     plt.subplots_adjust(wspace=0.25, hspace=0.35)
    # #
    # #     hd_range = list(date_range(start=hd_start, end=hd_end, freq=self.date_frequency).to_pydatetime())
    # #     plot_range = list(set(hd_range).intersection(self.date_time_span))
    # #     start_idx = self.date_time_span.index(plot_range[0]) - self.lag_order
    # #     end_idx = self.date_time_span.index(plot_range[-1]) - self.lag_order
    # #
    # #     hd_mat = np.zeros(len(shock_list) + 1, end_idx - start_idx + 1)
    # #     var_id = self.var_names.index(var)
    # #     i = 0
    # #     hd_resid = np.sum(self.hd_point_estimate[var_id, :, :], axis=2)
    # #     for shock in shock_list:
    # #         shock_id = self.shock_names.index(shock)
    # #         hd_mat[i, :] = self.hd_point_estimate[var_id, start_idx:end_idx + 1, shock_id]
    # #         hd_resid -= self.hd_point_estimate[var_id, start_idx:end_idx + 1, shock_id]
    # #         i += 1
    # #     hd_mat[i, :] = hd_resid
    # #
    # #     shock_list += ['resid']
    # #     for idxs, shock in enumerate(shock_list):
    # #         color = pt.BlueRed_6.mpl_colors[idxs]
    # #         if idxs == 0:
    # #             to_plot = hd_mat[idxs, :]
    # #             plt.bar(plot_range, to_plot, width=0.2, color=color, label=shock)
    # #             current = to_plot
    # #         else:
    # #             to_plot = hd_mat[idxs, :]
    # #             plt.bar(plot_range, to_plot, bottom=current, width=0.2, color=color, label=shock)
    # #             current = to_plot
    # #     ax = plt.figure
    # #     plt.xlim(0, h - 1)
    # #     plt.xticks(list(range(0, h, 5)))
    # #     plt.title(var, font_prop_title, pad=5.)
    # #     plt.tick_params(labelsize=25)
    # #     labels = ax.get_xticklabels() + ax.get_yticklabels()
    # #     [label.set_fontname('Palatino') for label in labels]
    # #     ax.set_xlabel(date_transfer_dict[self.date_frequency], fontdict=font_prop_xlabels, labelpad=1.)
    # #     plt.grid(linestyle='--', linewidth=1.5, color='black', alpha=0.35)
    # #     ax.spines['right'].set_visible(False)
    # #     ax.spines['top'].set_visible(False)
    # #     ax.spines['left'].set_linewidth(1.5)
    # #     ax.spines['bottom'].set_linewidth(1.5)
    # #
    # #     plt.suptitle('Historical Decomposition', fontproperties=font_prop_suptitle)
    # #     if save_path is not None:
    # #         full_path = save_path + '/historical_decomposition.png'
    # #         plt.savefig(full_path, bbox_inches='tight')
    # #     plt.show()


class SVAR:
    # TODO: check this
    # def __get_hd(self,
    #              shocks: np.ndarray,
    #              irfs: np.ndarray) -> np.ndarray:
    #     hd = np.zeros((self.n_vars, self.n_obs - self.lag_order, self.n_vars))
    #     for iperiod in range(self.n_obs - self.lag_order):
    #         for ishock in range(self.n_vars):
    #             for ivar in range(self.n_vars):
    #                 shocks_ = shocks[ishock, :iperiod]
    #                 hd[ivar, iperiod, ishock] = np.dot(irfs[ivar + ishock * self.n_vars, :iperiod], shocks_[::-1])
    #                 hd = hd.swapaxes(0, 2)
    #     return hd

    # TODO: check the logic
    # def hd(self,
    #        start: Optional[datetime.datetime] = None,
    #        end: Optional[datetime.datetime] = None) -> np.ndarray:
    #     if end <= start:
    #         raise ValueError('Invalid date!')
    #     if start < self.date_start:
    #         raise ValueError('Invalid date!')
    #     else:
    #         temp_idx = list(self.date_time_span).index(start)
    #         start_idx = temp_idx if temp_idx >= self.lag_order else temp_idx - self.lag_order
    #     if end > self.date_end:
    #         end_idx = -1
    #     else:
    #         end_idx = list(self.date_time_span).index(end)
    #     return self.hd_point_estimate[:, start_idx:end_idx + 1]

    # TODO: check the logic
    # def hd_cv(self,
    #           hd_sig: Union[List[int], int]) -> None:
    #     if 'vd_mat' not in self.__dir__():
    #         raise ValueError("bootstrap first")
    #     self.vd_confid_intvl = self._ReducedModel__make_confid_intvl(mat=self.hd_mat, sigs=hd_sig)
    #     if self.median_as_point_estimate:
    #         self.vd_point_estimate = np.percentile(self.hd_mat, 50, axis=0)


class SVAR(BaseModel):
    def __init__(self,
                 data: np.ndarray,
                 var_names: list,
                 shock_names: list,
                 date_frequency: Literal['D', 'W', 'M', 'Q', 'A'],
                 date_start: datetime.datetime,
                 date_end: datetime.datetime,
                 set_identified: bool,
                 lag_order: Optional[int] = None,
                 constant: bool = True,
                 info_criterion: Literal['aic', 'bic', 'hqc'] = 'aic'):
        super().__init__(data=data,
                         var_names=var_names,
                         date_frequency=date_frequency,
                         date_start=date_start,
                         date_end=date_end,
                         lag_order=lag_order,
                         constant=constant,
                         info_criterion=info_criterion)
        self.shock_names = shock_names
        self.n_shocks = len(shock_names)
        self.n_diff = self.n_vars - self.n_shocks
        self.H = self.n_obs - self.lag_order
        self.fit()
        # cholesky gives you the lower triangle in numpy
        self.chol = np.linalg.cholesky(self.cov_mat)
        self.plotter = Plotter(var_names=var_names,
                               shock_names=self.shock_names,
                               date_frequency=date_frequency)
        self.set_identified = set_identified

    def get_structural_shocks(self,
                              chol: Optional[np.ndarray] = None,
                              rotation: Optional[np.ndarray] = None,
                              resid: Optional[np.ndarray] = None) -> np.ndarray:
        if chol is None:
            chol = self.chol
        if rotation is None:
            rotation = self.rotation
        if resid is None:
            resid = self.resids
        shocks = np.dot(np.linalg.inv(np.dot(chol, rotation)), resid[self.lag_order:, :].T)
        return shocks

    def irf(self, h: int) -> np.ndarray:
        return self.irf_point_estimate[:, h + 1]

    def vd(self, h: int) -> np.ndarray:
        return self.vd_point_estimate[:, h + 1]

    def irf_cv(self, sigs: Union[List[int], int]) -> None:
        if 'irf_mat' not in self.__dir__():
            raise ValueError("bootstrap first")
        self.irf_confid_intvl = self.tool.make_confid_intvl(mat=self.irf_mat, sigs=sigs)
        if self.set_identified:
            self.irf_point_estimate = np.percentile(self.irf_mat, 50, axis=0)

    def vd_cv(self, sigs: Union[List[int], int]) -> None:
        if 'vd_mat' not in self.__dir__():
            raise ValueError("bootstrap first")
        self.vd_confid_intvl = self.tool.make_confid_intvl(mat=self.vd_mat, sigs=sigs)
        if self.set_identified:
            self.vd_point_estimate = np.percentile(self.vd_mat, 50, axis=0)

    # TODO: check this
    # def __get_hd(self,
    #              shocks: np.ndarray,
    #              irfs: np.ndarray) -> np.ndarray:
    #     hd = np.zeros((self.n_vars, self.n_obs - self.lag_order, self.n_vars))
    #     for iperiod in range(self.n_obs - self.lag_order):
    #         for ishock in range(self.n_vars):
    #             for ivar in range(self.n_vars):
    #                 shocks_ = shocks[ishock, :iperiod]
    #                 hd[ivar, iperiod, ishock] = np.dot(irfs[ivar + ishock * self.n_vars, :iperiod], shocks_[::-1])
    #                 hd = hd.swapaxes(0, 2)
    #     return hd

    # TODO: check the logic
    # def hd(self,
    #        start: Optional[datetime.datetime] = None,
    #        end: Optional[datetime.datetime] = None) -> np.ndarray:
    #     if end <= start:
    #         raise ValueError('Invalid date!')
    #     if start < self.date_start:
    #         raise ValueError('Invalid date!')
    #     else:
    #         temp_idx = list(self.date_time_span).index(start)
    #         start_idx = temp_idx if temp_idx >= self.lag_order else temp_idx - self.lag_order
    #     if end > self.date_end:
    #         end_idx = -1
    #     else:
    #         end_idx = list(self.date_time_span).index(end)
    #     return self.hd_point_estimate[:, start_idx:end_idx + 1]

    # TODO: check the logic
    # def hd_cv(self,
    #           hd_sig: Union[List[int], int]) -> None:
    #     if 'vd_mat' not in self.__dir__():
    #         raise ValueError("bootstrap first")
    #     self.vd_confid_intvl = self._ReducedModel__make_confid_intvl(mat=self.hd_mat, sigs=hd_sig)
    #     if self.median_as_point_estimate:
    #         self.vd_point_estimate = np.percentile(self.hd_mat, 50, axis=0)

    def plot_irf(self,
                 var_list: Optional[List[str]] = None,
                 shock_list: Union[List[int]] = None,
                 sigs: Union[List[int], int] = None,
                 max_cols: int = 3,
                 with_ci: bool = True,
                 save_path: Optional[str] = None) -> None:
        if 'irf_point_estimate' not in self.__dir__():
            raise ValueError("IRFs should be estimated.")

        if with_ci:
            if sigs is None:
                raise ValueError('Not specifying significance levels.')
            if not isinstance(sigs, list):
                sigs = [sigs]
            if 'irf_confid_intvl' not in self.__dir__():
                self.irf_cv(sigs)

        if self.irf_point_estimate.shape[1] != self.irf_mat.shape[2]:
            print('Warning: length for point estimate and confidence interval are not consistent!')
            H = min(self.irf_point_estimate.shape[1], self.irf_mat.shape[2])
        else:
            H = self.irf_point_estimate.shape[1]
        # H contains the init period
        irf_plot = self.irf_point_estimate[:, :H]
        for sig in sigs:
            for bound in ['lower', 'upper']:
                self.irf_confid_intvl[sig][bound] = self.irf_confid_intvl[sig][bound][:, :H]

        if var_list is None:
            var_list = self.var_names
        elif not set(var_list).issubset(set(self.var_names)):
            raise ValueError('Check the variable names!')
        else:
            pass

        if shock_list is None:
            shock_list = self.shock_names
        elif not set(shock_list).issubset(set(range(self.n_vars))):
            raise ValueError('Check the shock names!')
        else:
            pass

        self.plotter.plot_irf(h=H,
                              var_list=var_list,
                              shock_list=shock_list,
                              sigs=sigs,
                              irf=irf_plot,
                              with_ci=with_ci,
                              max_cols=max_cols,
                              irf_cv=self.irf_confid_intvl,
                              save_path=save_path)

    def plot_vd(self,
                var_list: Optional[List[str]] = None,
                shock_list: Optional[List[int]] = None,
                max_cols: int = 3,
                save_path: Optional[str] = None) -> None:
        if 'vd_point_estimate' not in self.__dir__():
            raise ValueError("IRFs should be estimated.")

        if var_list is None:
            var_list = self.var_names
        elif not set(var_list).issubset(set(self.var_names)):
            raise ValueError('Check the variable names!')
        else:
            pass

        if shock_list is None:
            shock_list = self.shock_names
        elif not set(shock_list).issubset(set(range(self.n_vars))):
            raise ValueError(f'The system only allows {self.n_vars} orthogonal shocks!')
        else:
            pass

        H = self.vd_point_estimate.shape[1]
        self.plotter.plot_vd(h=H,
                             var_list=var_list,
                             shock_list=shock_list,
                             vd=self.vd_point_estimate,
                             max_cols=max_cols,
                             save_path=save_path)


SVAR -> irf
        # if 'irf_mat' not in self.__dir__():
        #     raise ValueError("Model is not identified.")
        # if sigs is not None:
        #     self.irf_confid_intvl = self.tool.make_confid_intvl(mat=self.irf_mat, sigs=sigs)
        # if how == 'median':
        #     self.irf_point_estimate = np.percentile(self.irf_mat, 50, axis=0)
        # elif how == 'average':
        #     self.irf_point_estimate = np.sum(self.irf_mat, axis=0) / self.irf_mat.shape[0]
        # return self.irf_point_estimate[:, h + 1]

VAR
    def irf_cv(self,
               h: int,
               sigs: Union[List[int], int]) -> dict:
        if 'irf_mat_full' not in self.__dir__():
            raise ValueError("bootstrap first")
        self.irf_confid_intvl = self.tool.make_confid_intvl(mat=self.irf_mat_full[:, :h + 1], sigs=sigs)
        return self.irf_confid_intvl

    def vd_cv(self,
              h: int,
              sigs: Union[List[int], int]) -> dict:
        if 'vd_mat_full' not in self.__dir__():
            raise ValueError("bootstrap first")
        self.vd_confid_intvl = self.tool.make_confid_intvl(mat=self.vd_mat_full[:, :h + 1], sigs=sigs)
        return self.vd_confid_intvl


VAR -> bootstrap
        if seed:
            np.random.seed(seed)
            random.seed(seed)

        # self.irf_mat = np.zeros((n_path, self.n_vars ** 2, h + 1))
        # self.vd_mat = np.zeros((n_path, self.n_vars ** 2, h + 1))
        self.irf_mat_full = np.zeros((n_path, self.n_vars ** 2, self.H + 1))
        self.vd_mat_full = np.zeros((n_path, self.n_vars ** 2, self.H + 1))

        for r in range(n_path):
            yr = self.make_bootstrap_sample()
            comp_mat_r, cov_mat_r, _, _, _ = self.estimate(yr, self.lag_order)
            cov_mat_r = cov_mat_r[:self.n_vars, :self.n_vars]
            self.tool.update(data=yr, comp=comp_mat_r, cov=cov_mat_r)
            self.tool.estimate_irf()
            self.irf_mat_full[r, :, :] = self.tool.irf
            self.vd_mat_full[r, :, :] = self.tool.estimate_vd(self.tool.irf)
            # irfr = self.tool.irf
            # self.irf_mat_full[r, :, :] = irfr
            # temp_irfr = irfr[:, :h + 1]
            # self.irf_mat[r, :, :] = temp_irfr
            # vdr = self.tool.estimate_vd(temp_irfr)
            # self.vd_mat[r, :, :] = vdr

SignRestriction -> identify
            if seed:
            np.random.seed(seed)
            random.seed(seed)

        counter = 0
        total = 0
        self.rotation_list = []

        while counter < n_rotation:
            total += 1
            D = self.draw_rotation()
            self.tool.update(rotation=D)
            self.tool.estimate_irf(length=length_to_check)
            _irfs_ = self.tool.irf
            irf_sign = np.sign(np.sum(_irfs_, axis=1).reshape((self.n_vars, self.n_vars)))
            idx, sorted_signs = self._sort_row(irf_sign)
            diff_sign = self.target_signs - sorted_signs
            if np.sum(diff_sign ** 2) == self.num_unrestricted:
                counter += 1
                if verbose:
                    print(f'{counter} accepted rotations/{n_rotation} required rotations')
                D = D[:, idx]
                self.rotation_list.append(D)
                # self.tool.update(rotation=D)
                # irfr_full = self.tool.irf
                # self.irf_full_mat[counter - 1, :, :] = irfr_full[:(self.n_vars ** 2 - self.n_diff * self.n_vars), :]
                # # irf_needed = irfr_full[:, :h + 1]
                # # self.irf_mat[counter - 1, :, :] = irf_needed[:(self.n_vars ** 2 - self.n_diff * self.n_vars), :]
                # vdr = self.tool.estimate_vd(irfs=irfr_full)
                # self.vd_mat[counter - 1, :, :] = vdr[:(self.n_vars ** 2 - self.n_diff * self.n_vars), :]


PointIdentifiesSVAR:
    def bootstrap(self,
                  n_path: int,
                  seed: Union[bool, int] = False) -> None:
        if seed:
            np.random.seed(seed)
            random.seed(seed)

        self.irf_mat = np.zeros((n_path, self.n_vars ** 2, h + 1))
        self.vd_mat = np.zeros((n_path, self.n_vars ** 2, h + 1))
        self.irf_max_mat = np.zeros((n_path, self.n_vars ** 2, self.H + 1))
        self.shock_mat = np.zeros((n_path, self.H, self.n_vars))
        self.rotation_mat = np.zeros((n_path, self.n_vars, self.n_vars))
        zs = np.zeros((self.lag_order, self.n_vars))

        for r in range(n_path):
            yr = self._ReducedModel__make_bootstrap_sample()
            comp_mat_r, cov_mat_r, res_r, _, _ = self._Estimation__estimate(yr, self.lag_order)
            cov_mat_r = cov_mat_r[:self.n_vars, :self.n_vars]
            rotationr = self.solve(comp_mat=comp_mat_r, cov_mat=cov_mat_r)
            self.rotation_mat[r, :, :] = rotationr
            irfr = self._ReducedModel__get_irf(h=self.H, rotation=rotationr, comp_mat=comp_mat_r, cov_mat=cov_mat_r)
            self.irf_max_mat[r, :, :] = irfr
            _irfr = irfr[:, :h + 1]
            self.irf_mat[r, :, :] = _irfr
            vdr = self._ReducedModel__get_vd(irfs=_irfr)
            self.vd_mat[r, :, :] = vdr
            # TODO: think about how to get HDs
            # resids_r = np.concatenate((zs, res_r[:self.n_vars, :].T), axis=0)  # this is the true residuals
            # shock_r = self.get_structural_shocks(chol=np.linalg.cholesky(cov_mat_r), rotation=rotationr, resid=resids_r)
            # self.shock_mat[r, :, :] = shock_r
            # self.hd_mat[r, :, :] = self.__get_hd(shock_r, irfr)

class SetIdentifiedSVAR(SVAR):
    def __init__(self,
                 data: np.ndarray,
                 var_names: list,
                 shock_names: list,
                 date_frequency: Literal['D', 'W', 'M', 'Q', 'A'],
                 date_start: datetime.datetime,
                 date_end: datetime.datetime,
                 lag_order: Optional[int] = None,
                 constant: bool = True,
                 info_criterion: Literal['aic', 'bic', 'hqc'] = 'aic'):
        super().__init__(data=data,
                         var_names=var_names,
                         shock_names=shock_names,
                         date_frequency=date_frequency,
                         date_start=date_start,
                         date_end=date_end,
                         lag_order=lag_order,
                         constant=constant,
                         info_criterion=info_criterion)
        self.shock_names = shock_names
        self.n_shocks = len(shock_names)
        self.n_diff = self.n_vars - self.n_shocks
        self.H = self.n_obs - self.lag_order
        self.fit()
        # cholesky gives you the lower triangle in numpy
        self.chol = np.linalg.cholesky(self.cov_mat)
        self.plotter = Plotter(var_names=var_names,
                               shock_names=self.shock_names,
                               date_frequency=date_frequency)
        self.tool = Tools(data=data,
                          lag_order=self.lag_order,
                          comp_mat=self.comp_mat,
                          cov_mat=self.cov_mat)

    def get_structural_shocks(self,
                              chol: Union[np.ndarray, None],
                              rotation: Union[np.ndarray, None],
                              resid: Union[np.ndarray, None]) -> np.ndarray:
        if chol is None:
            chol = self.chol
        if rotation is None:
            rotation = self.rotation
        if resid is None:
            resid = self.resids
        shocks = np.dot(np.linalg.inv(np.dot(chol, rotation)), resid[self.lag_order:, :].T)
        return shocks

    def full_irf(self) -> None:
        n_rotation = len(self.rotation_list)
        self.irf_mat_full = np.zeros((n_rotation, self.n_vars ** 2, self.H + 1))
        self.vd_mat_full = np.zeros((n_rotation, self.n_vars ** 2, self.H + 1))
        counter = 1
        for rotation in self.rotation_list:
            self.tool.update(rotation=rotation)
            self.tool.estimate_irf()
            self.irf_mat_full[counter - 1, :, :] = self.tool.irf
            self.vd_mat_full[counter - 1, :, :] = self.tool.estimate_vd(irfs=self.tool.irf)
            counter += 1

    def irf(self,
            h: int,
            how: Literal['median', 'average'] = 'median') -> np.ndarray:
        if 'irf_mat_full' not in self.__dir__():
            raise ValueError("Model is not identified.")
        if how == 'median':
            self.irf_point_estimate = np.percentile(self.irf_mat_full, 50, axis=0)
        elif how == 'average':
            self.irf_point_estimate = np.sum(self.irf_mat_full, axis=0) / self.irf_mat_full.shape[0]
        return self.irf_point_estimate[:(self.n_vars ** 2 - self.n_diff * self.n_vars), :h + 1]

    def vd(self,
           h: int,
           how: Literal['median', 'average'] = 'median') -> np.ndarray:
        if 'vd_mat_full' not in self.__dir__():
            raise ValueError("Model is not identified.")
        if how == 'median':
            self.vd_point_estimate = np.percentile(self.vd_mat_full, 50, axis=0)
        elif how == 'average':
            self.vd_point_estimate = np.sum(self.vd_mat_full, axis=0) / self.vd_mat_full.shape[0]
        return self.vd_point_estimate[:(self.n_vars ** 2 - self.n_diff * self.n_vars), :h + 1]

    def calc_confid_intvl(self,
                          h: int,
                          which: Literal['irf', 'vd'],
                          sigs: Union[List[int], int]) -> dict:
        if which == 'irf':
            if 'irf_mat_full' not in self.__dir__():
                raise ValueError("bootstrap first")
            mat = self.irf_mat_full[:, :(self.n_vars ** 2 - self.n_diff * self.n_vars), :h + 1]
        else:
            if 'vd_mat_full' not in self.__dir__():
                raise ValueError("bootstrap first")
            mat = self.irf_mat_full[:, :(self.n_vars ** 2 - self.n_diff * self.n_vars), :h + 1]
        return self.tool.make_confid_intvl(mat=mat, sigs=sigs)

    def plot_irf(self,
                 h: int,
                 sigs: Union[List[int], int] = None,
                 var_list: Optional[List[str]] = None,
                 shock_list: Optional[List[str]] = None,
                 max_cols: int = 3,
                 with_cv: bool = True,
                 save_path: Optional[str] = None) -> None:
        if 'irf_point_estimate' not in self.__dir__():
            raise ValueError("IRFs should be estimated.")

        if with_cv:
            if sigs is None:
                raise ValueError('Not specifying significance levels.')
            if not isinstance(sigs, list):
                sigs = [sigs]
            cv_plot = self.calc_confid_intvl(h=h, which='irf', sigs=sigs)
        else:
            cv_plot = None

        irf_plot = self.irf_point_estimate[:, :h + 1]

        if var_list is None:
            var_list = self.var_names
        elif not set(var_list).issubset(set(self.var_names)):
            raise ValueError('Check the variable names!')
        else:
            pass

        if shock_list is None:
            shock_list = self.shock_names
        elif not set(shock_list).issubset(set(self.shock_names)):
            raise ValueError('Check the shock names!')
        else:
            pass

        self.plotter.plot_irf(h=h + 1,
                              var_list=var_list,
                              shock_list=shock_list,
                              sigs=sigs,
                              irf=irf_plot,
                              with_ci=True,
                              max_cols=max_cols,
                              irf_cv=cv_plot,
                              save_path=save_path)

    def plot_vd(self,
                h: int,
                var_list: Optional[List[str]] = None,
                shock_list: Optional[List[int]] = None,
                max_cols: int = 3,
                save_path: Optional[str] = None) -> None:
        if 'vd_point_estimate' not in self.__dir__():
            raise ValueError("IRFs should be estimated.")

        if var_list is None:
            var_list = self.var_names
        elif not set(var_list).issubset(set(self.var_names)):
            raise ValueError('Check the variable names!')
        else:
            pass

        if shock_list is None:
            shock_list = self.shock_names
        elif not set(shock_list).issubset(set(range(self.n_vars))):
            raise ValueError(f'The system only allows {self.n_vars} orthogonal shocks!')
        else:
            pass

        self.plotter.plot_vd(h=h + 1,
                             var_list=var_list,
                             shock_list=shock_list,
                             vd=self.vd_point_estimate[:h + 1],
                             max_cols=max_cols,
                             save_path=save_path)


def get_structural_shocks()

import numpy as np
import scipy.io as spio
resid = spio.loadmat('/Users/fangli/PySVAR/PySVAR/data/resid.mat')['usim']
irf = spio.loadmat('/Users/fangli/PySVAR/PySVAR/data/irf.mat')['IRF']
rotation = spio.loadmat('/Users/fangli/PySVAR/PySVAR/data/rotation.mat')['Q']
chol = spio.loadmat('/Users/fangli/PySVAR/PySVAR/data/chol.mat')['cdc']
shocks = np.dot(np.linalg.inv(np.dot(chol, rotation)), resid.T)
